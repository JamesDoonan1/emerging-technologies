{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trigram-Based Model for Text Analysis and Generation\n",
    "\n",
    "This Jupyter Notebook demonstrates the process of building and utilizing a trigram-based model for text analysis and generation. The workflow includes the following steps:\n",
    "\n",
    "- **Cleaning and Preprocessing of Text Data from Project Gutenberg**:\n",
    "    - Load and clean text data from Project Gutenberg to prepare it for analysis.\n",
    "    - Remove unwanted characters and normalize the text.\n",
    "\n",
    "- **Building a Trigram Model for Patterns in English**:\n",
    "    - Construct a trigram model to capture patterns of three consecutive characters in the cleaned text.\n",
    "    - Count the occurrences of each trigram to understand the frequency of character sequences.\n",
    "\n",
    "- **Generating Text Using the Trigram Model**:\n",
    "    - Use the trigram model to generate new text that mimics the style and structure of the original text.\n",
    "    - Implement a function to produce a specified length of text based on the trigram probabilities.\n",
    "\n",
    "- **Analyzing the Validity of Generated Text**:\n",
    "    - Evaluate the generated text by calculating the percentage of valid English words.\n",
    "    - Compare the generated text to a dictionary of valid words to assess its coherence.\n",
    "\n",
    "- **Exporting the Trigram Model in JSON Format**:\n",
    "    - Save the trigram model to a JSON file for future use and sharing.\n",
    "    - Ensure the model is easily accessible and reusable.\n",
    "\n",
    "This notebook provides a comprehensive guide to creating and utilizing a trigram-based model for text analysis and generation, offering insights into the patterns and structures of English text.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Third-order Letter Approximation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import string\n",
    "import json\n",
    "import unittest\n",
    "from unittest.mock import patch\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `clean_text` function\n",
    "Cleans the input text by performing the following operations:\n",
    "1. Replaces newline characters with spaces.\n",
    "2. Removes non-alphabetic characters, keeping only uppercase letters, spaces, and full stops.\n",
    "3. Replaces multiple consecutive spaces with a single space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 1: Load and Clean the Text\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Cleans the input text by performing the following operations:\n",
    "    1. Replaces newline characters with spaces.\n",
    "    2. Removes non-alphabetic characters, keeping only uppercase letters, spaces, and full stops.\n",
    "    3. Replaces multiple spaces with a single space.\n",
    "    Args:\n",
    "        text (str): The input text to be cleaned.\n",
    "    Returns:\n",
    "        str: The cleaned text.\n",
    "    \"\"\"\n",
    "    # Replace newlines with spaces.\n",
    "    text = text.replace('\\n', ' ')\n",
    "                        \n",
    "    # Remove non-alphabetic characters. Keep letters, spaces and full stops\n",
    "    cleaned = re.sub(r'[^A-Z\\s.]','', text.upper())\n",
    "\n",
    "    # Replace multiple spaces with a single space\n",
    "    cleaned = re.sub(r'\\s+',' ',cleaned).strip()\n",
    "\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `process_file` Function\n",
    "\n",
    "The `process_file` function is designed to load and clean the text from a specified file. Below is an example of how to use this function on a single file:\n",
    "\n",
    "1. **Load and Clean the Text**:\n",
    "    - The function reads the content of the file located at the specified path.\n",
    "    - It searches for specific start and end markers to extract the main content.\n",
    "    - The extracted text is then cleaned using the `clean_text` function.\n",
    "\n",
    "2. **Example Usage**:\n",
    "    - In this example, the text is loaded and cleaned from the file `frankenstein.txt` located in the `gutenbergtexts` directory.\n",
    "    - The first 500 characters of the cleaned text are displayed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load in Text files and clean them\n",
    "\n",
    "def process_file(file_path):\n",
    "    \"\"\"\n",
    "    Processes a text file by extracting and cleaning its content.\n",
    "\n",
    "    This function reads the content of a text file located at the specified \n",
    "    'file_path'. It searches for the standard Project Gutenberg start and end \n",
    "    markers to extract the main content of the text. If the markers are found, \n",
    "    the text between them is extracted. If the markers are not found, a warning \n",
    "    message is printed. The extracted text is then cleaned and returned.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the text file to be processed.\n",
    "\n",
    "    Returns:    \n",
    "        str: The cleaned text extracted from the file.\n",
    "    \"\"\"\n",
    "    # Open the file located at 'file_path' in read mode with utf-8 encoding\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        # Read the entire content of the file into the variable 'text'\n",
    "        text = f.read()\n",
    "\n",
    "    # Search for the start marker indicating the beginning\n",
    "    start_marker = re.search(r\"\\*\\*\\* START OF (THE|THIS) PROJECT GUTENBERG EBOOK.*\\*\\*\\*\", text)\n",
    "    # Search for the end marker indicating the end of the content\n",
    "    end_marker = re.search(r\"\\*\\*\\* END OF (THE|THIS) PROJECT GUTENBERG EBOOK.*\\*\\*\\*\", text)\n",
    "\n",
    "    # If both the start and end markers are found, extract the text between them\n",
    "    if start_marker and end_marker:\n",
    "        text = text[start_marker.end():end_marker.start()]\n",
    "    else:\n",
    "        # If markers are not found, print a warning message\n",
    "        print(\"Warning: Could not find standard Project Gutenberg markers.\")\n",
    "\n",
    "    # Clean the text\n",
    "    return clean_text(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Example of how to use the function on a single file:\n",
    "\n",
    "* **Example Usage**:\n",
    "    - In this example, the trigram model is built from the cleaned text of `frankenstein.txt`.\n",
    "    - The first 10 trigram counts from the model are displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ********** Example of how to use the function on a single file:  *********************\n",
    "\n",
    "# Load and clean the text from a file (in this case, 'Frankenstein')\n",
    "# cleaned_text = process_file('gutenbergtexts/frankenstein.txt')\n",
    "\n",
    "# Display the first 500 characters of Frankenstein\n",
    "# print(cleaned_text[:500])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `build_trigram_model` Function\n",
    "\n",
    "The `build_trigram_model` function constructs a trigram model from the given cleaned text. A trigram model is a dictionary where the keys are trigrams (3-character sequences) and the values are the counts of how often each trigram appears in the text.\n",
    "\n",
    "#### Explanation\n",
    "1. **Initialization**: A dictionary `trigram_counts` is initialized to count the occurrences of each trigram.\n",
    "2. **Trigram Creation**: The function loops through the text to create trigrams. A trigram consists of 3 consecutive characters, so the loop stops 2 characters before the end to avoid index out-of-range errors.\n",
    "3. **Count Incrementation**: For each trigram, the count in the dictionary is incremented.\n",
    "4. **Return**: The dictionary of trigram counts is returned.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build a trigram model from the cleaned text\n",
    "def build_trigram_model(cleaned_text):\n",
    "    \"\"\"\n",
    "    Builds a trigram model from the given cleaned text.\n",
    "\n",
    "    A trigram model is a dictionary where the keys are trigrams (3-character sequences)\n",
    "    and the values are the counts of how often each trigram appears in the text.\n",
    "\n",
    "    Args:\n",
    "        cleaned_text (str): The input text from which to build the trigram model. \n",
    "                            It should be preprocessed and cleaned.\n",
    "\n",
    "    Returns:\n",
    "        defaultdict: A dictionary with trigrams as keys and their occurrence counts as values.\n",
    "    \"\"\"\n",
    "    # Initialize a dictionary to count the occurrences of each trigram\n",
    "    trigram_counts = defaultdict(int)\n",
    "\n",
    "    # Loop through the text and the create trigrams\n",
    "    # A trigram consists of 3 consecutive characters, so we iterate over the text, \n",
    "    # stopping 2 characters before the end to avoid index out-of-range errors\n",
    "    for i in range(len(cleaned_text) -2):\n",
    "        # Extract the current trigram (3-character sequence)\n",
    "        trigram = cleaned_text[i:i+3]\n",
    "        # Increment the count of this trigram in the dictionary\n",
    "        trigram_counts[trigram] += 1\n",
    "\n",
    "    # Return the dictionary of trigram counts\n",
    "    return trigram_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `process_multiple_files` function\n",
    "\n",
    "Description\n",
    "This function takes a list of file paths, processes each file to clean the text, builds a trigram model for each file, and then combines the trigram counts from all files into a single dictionary. The combined trigram counts are returned as the output.\n",
    "\n",
    "1. **Clean the Text**: It processes each file to clean the text, which typically involves removing unwanted characters, converting text to lowercase, etc.\n",
    "2. **Build Trigram Model**: For each cleaned text, it constructs a trigram model. A trigram is a sequence of three consecutive words, and the model counts the occurrences of each trigram.\n",
    "3. **Combine Trigram Counts**: It then combines the trigram counts from all the processed files into a single dictionary. This dictionary accumulates the counts of each trigram across all files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process multiple text files and build a combined trigram model\n",
    "def process_multiple_files(file_paths):\n",
    "    \"\"\"\n",
    "    Processes multiple text files to build a combined trigram model.\n",
    "    This function takes a list of file paths, processes each file to clean the text,\n",
    "    builds a trigram model for each file, and then combines the trigram counts from\n",
    "    all files into a single dictionary.\n",
    "    Args:\n",
    "        file_paths (list of str): A list of file paths to the text files to be processed.\n",
    "    Returns:\n",
    "        defaultdict: A dictionary containing the combined trigram counts from all files,\n",
    "                     where the keys are trigrams (tuples of three words) and the values\n",
    "                     are the counts of those trigrams across all files.\n",
    "    \"\"\"\n",
    "    # Initialize a dictionary to store trigram counts across all files\n",
    "    combined_trigram_counts = defaultdict(int)\n",
    "\n",
    "    # Loop through the list of file paths\n",
    "    for file_path in file_paths:\n",
    "\n",
    "        # Process/Clean the file\n",
    "        cleaned_text = process_file(file_path)\n",
    "\n",
    "        # Build trigram model for the current file\n",
    "        trigram_counts = build_trigram_model(cleaned_text)\n",
    "\n",
    "\n",
    "        # Merge the trigram counts from this file into the combined count\n",
    "        for trigram, count in trigram_counts.items():\n",
    "            combined_trigram_counts[trigram] += count\n",
    "        \n",
    "    # Return the combined trigram counts from all files\n",
    "    return combined_trigram_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "List all file paths for 5 different books from Project Gutenberg and process them to build a combined trigram model.\n",
    "\n",
    "The function performs the following steps:\n",
    "1. Lists the file paths for five books from Project Gutenberg.\n",
    "2. Processes all the files and builds a combined trigram model from the listed file paths.\n",
    "3. Displays the first 10 trigram counts from the combined trigram model.\n",
    "\n",
    "File paths:\n",
    "- 'gutenbergtexts/frankenstein.txt'\n",
    "- 'gutenbergtexts/mobydick.txt'\n",
    "- 'gutenbergtexts/prideandprejudice.txt'\n",
    "- 'gutenbergtexts/romeoandjuliet.txt'\n",
    "- 'gutenbergtexts/scarletletter.txt'\n",
    "\n",
    "The combined trigram model is created by calling the `process_multiple_files` function with the list of file paths.\n",
    "The first 10 trigram counts from the combined trigram model are displayed by converting the model to a list of tuples and printing the first 10 items.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LET': 1288, 'ETT': 997, 'TTE': 2141, 'TER': 7254, 'ER ': 17193, 'R T': 4524, ' TO': 16087, 'TO ': 14617, 'O M': 1842, ' MR': 1372, 'MRS': 374, 'RS.': 716, 'S. ': 3141, '. S': 1466, ' SA': 3993, 'SAV': 180, 'AVI': 512, 'VIL': 479, 'ILL': 3706, 'LLE': 1195, 'LE ': 6435, 'E E': 2250, ' EN': 2286, 'ENG': 723, 'NGL': 984, 'GLA': 350, 'LAN': 1307, 'AND': 19336, 'ND.': 311, 'D. ': 1902, ' ST': 5071, 'ST.': 309, 'T. ': 2434, '. P': 340, ' PE': 2722, 'PET': 180, 'ETE': 587, 'ERS': 3578, 'RSB': 3, 'SBU': 18, 'BUR': 315, 'URG': 149, 'RGH': 64, 'GH ': 1784, 'H D': 294, ' DE': 4535, 'DEC': 579, 'EC.': 3, 'C. ': 70, '. T': 3299, ' TH': 55430, 'TH ': 7714, 'H .': 11, ' . ': 311, '. Y': 568, ' YO': 5124, 'YOU': 5050, 'OU ': 3929, 'U W': 495, ' WI': 8644, 'WIL': 1842, 'LL ': 7835, 'L R': 313, ' RE': 6192, 'REJ': 103, 'EJO': 52, 'JOI': 192, 'OIC': 276, 'ICE': 1039, 'CE ': 4594, 'E T': 10499, 'O H': 1994, ' HE': 13123, 'HEA': 2504, 'EAR': 4471, 'AR ': 2179, 'THA': 8516, 'HAT': 9320, 'AT ': 12970, 'T N': 1158, ' NO': 8420, 'NO ': 1598, 'O D': 914, ' DI': 3600, 'DIS': 1540, 'ISA': 220, 'SAS': 35, 'AST': 2488, 'STE': 3085, 'R H': 2077, ' HA': 10254, 'HAS': 1089, 'AS ': 11125, 'S A': 7602, ' AC': 1208, 'ACC': 641, 'CCO': 386, 'COM': 2658, 'OMP': 944, 'MPA': 599}\n"
     ]
    }
   ],
   "source": [
    "# List all file paths for 5 different books from Project Gutenberg\n",
    "file_paths = [\n",
    "    'gutenbergtexts/frankenstein.txt',\n",
    "    'gutenbergtexts/mobydick.txt',\n",
    "    'gutenbergtexts/prideandprejudice.txt',\n",
    "    'gutenbergtexts/romeoandjuliet.txt',\n",
    "    'gutenbergtexts/scarletletter.txt'\n",
    "]\n",
    "\n",
    "# Process all the files and build a combined trigram model from the listed file paths\n",
    "combined_trigram_model = process_multiple_files(file_paths)\n",
    "\n",
    "# Display the first 10 trigram counts from the combined trigram model\n",
    "print(dict(list(combined_trigram_model.items())[:100])) # Convert to a list of tuples and display the first 10 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Third-order letter approximation generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `print_trigram_possibilities` function\n",
    "\n",
    "Steps\n",
    "1. Filter Trigrams:\n",
    "\n",
    "2. The function searches the trigram_model dictionary for trigrams that start with the given pair of characters (last_two).\n",
    "These matching trigrams and their counts are stored in the possible_trigrams dictionary.\n",
    "Extract and Count:\n",
    "\n",
    "3. The function extracts the third character (the next possible character) from each matching trigram.\n",
    "Counts the occurrences of each matching trigram.\n",
    "Calculate Probabilities:\n",
    "\n",
    "4. Computes the probability of each next character by dividing the count of each trigram by the total count of all matching trigrams.\n",
    "Print Results:\n",
    "\n",
    "5. For each next character, the function prints the following:\n",
    "The trigram (formed by combining last_two and the next character).\n",
    "The count of the trigram.\n",
    "The probability of the trigram.\n",
    "Handle Missing Data:\n",
    "\n",
    "6. If no trigrams start with last_two, the function prints a message and exits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trigram_possibilities(trigram_model, last_two):\n",
    "    \"\"\"\n",
    "    Prints the possible next characters for a given pair of characters (last_two)\n",
    "    and their probabilities based on the trigram model.\n",
    "    \n",
    "    Args:\n",
    "        trigram_model (dict): The trigram model containing counts of trigrams.\n",
    "        last_two (str): The last two characters (e.g., 'TH') for which to calculate next character probabilities.\n",
    "    \"\"\"\n",
    "\n",
    "    # Find all trigrams with the given two characters\n",
    "    possible_trigrams = {trigram: count for trigram, count in trigram_model.items() if trigram.startswith(last_two)}\n",
    "\n",
    "    if not possible_trigrams:\n",
    "        print(f\"No trigrams found starting with '{last_two}'.\")\n",
    "        return\n",
    "    \n",
    "    # Seperate the third letter and their respective counts\n",
    "    letters = [trigram[2] for trigram in possible_trigrams.keys() ]\n",
    "    counts = list(possible_trigrams.values())\n",
    "\n",
    "    # Calculate the total count of occurrence's for normalisation\n",
    "    total_count = sum(counts)\n",
    "\n",
    "    # Print the possibilities\n",
    "    print(f\"Possible next characters after '{last_two}':\")\n",
    "    for letter, count in zip(letters, counts):\n",
    "        probability = count / total_count\n",
    "        print(f\"{last_two + letter}: appeared {count} times, probability = {probability:.4f}\")\n",
    "    print(f\"Total occurrences; {total_count}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `generate_text` function\n",
    "\n",
    "The generated text was analyzed to determine the percentage of valid English words. The analysis involved the following steps:\n",
    "\n",
    "1. **Loading Valid Words**:\n",
    "    - A set of valid English words was loaded from the `words.txt` file.\n",
    "\n",
    "2. **Generating Text**:\n",
    "    - Text was generated using the trigram model built from the combined text of five books from Project Gutenberg.\n",
    "\n",
    "3. **Calculating Word Percentage**:\n",
    "    - The generated text was processed to extract individual words.\n",
    "    - Each word was checked against the set of valid English words.\n",
    "    - The percentage of valid English words in the generated text was calculated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated text (first 500 characters):\n",
      "THE BY PROME MATHER AN INFRIESS THE PERS WAS CAUT RUFFER THE FERCLIS THE TEATED \n",
      "LADARE SUPONLY WITHYST. AND STECT REACK OVIS LIFIR. WITS WAS AYSEETHIS PLIGHBOAR\n",
      "BETTLE THE BE LIM AITHE THE WOR DOSSIBEW SMAIN OF YOUT APPON UPOSIMED REMED THIS\n",
      "HE CH A CON EXAM OFBAT SHOSTON ALETTED THATILD ME AMP BE HORSE WAS GLET HADY AD \n",
      "BALLAM THATURINTATE SO LEN WHING TURNMIS BY HADDED SLOVELL WARK AN HIMINE BOU CA\n",
      "ND BE WAS STERED BLE IT REVOULD SMAD TOU HOW ON ANOW LING FRIBLAYSE SHAS OCCULOO\n",
      " MANDUCCULTER \n",
      "\n",
      "\n",
      "\n",
      "Possible next characters after 'TH':\n",
      "TH : appeared 7714 times, probability = 0.1080\n",
      "THA: appeared 8516 times, probability = 0.1192\n",
      "THE: appeared 42957 times, probability = 0.6013\n",
      "THI: appeared 5546 times, probability = 0.0776\n",
      "THO: appeared 3509 times, probability = 0.0491\n",
      "THS: appeared 291 times, probability = 0.0041\n",
      "THU: appeared 437 times, probability = 0.0061\n",
      "THR: appeared 1257 times, probability = 0.0176\n",
      "TH.: appeared 290 times, probability = 0.0041\n",
      "THY: appeared 561 times, probability = 0.0079\n",
      "THW: appeared 70 times, probability = 0.0010\n",
      "THL: appeared 94 times, probability = 0.0013\n",
      "THB: appeared 7 times, probability = 0.0001\n",
      "THQ: appeared 9 times, probability = 0.0001\n",
      "THD: appeared 59 times, probability = 0.0008\n",
      "THF: appeared 63 times, probability = 0.0009\n",
      "THH: appeared 17 times, probability = 0.0002\n",
      "THK: appeared 4 times, probability = 0.0001\n",
      "THG: appeared 4 times, probability = 0.0001\n",
      "THT: appeared 15 times, probability = 0.0002\n",
      "THP: appeared 7 times, probability = 0.0001\n",
      "THC: appeared 6 times, probability = 0.0001\n",
      "THN: appeared 2 times, probability = 0.0000\n",
      "THM: appeared 9 times, probability = 0.0001\n",
      "Total occurrences; 71444\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def generate_text(trigram_model, length=10000, line_length=80):\n",
    "    \"\"\"\n",
    "    Generates a text string based on a trigram model.\n",
    "    Args:\n",
    "        trigram_model (dict): A dictionary where keys are trigrams (strings of three characters)\n",
    "                              and values are their respective counts or probabilities.\n",
    "        length (int, optional): The desired length of the generated text. Default is 10,000 characters.\n",
    "        line_length (int, optional): The length of each line in the formatted output text. Default is 80 characters.\n",
    "    Returns:\n",
    "        str: A generated text string based on the trigram model, formatted with line breaks at the specified line length.\n",
    "    Notes:\n",
    "        - The function starts generating text with the string \"TH\".\n",
    "        - It continues generating characters based on the trigram model until the desired length is reached.\n",
    "        - If no trigrams are found for the last two characters in the generated text, the generation process stops.\n",
    "        - The generated text is formatted with line breaks at the specified line length.\n",
    "    \"\"\"\n",
    "    # Start with the string \"TH\" \n",
    "    generated_text = \"TH\"\n",
    "\n",
    "    # Continue generating characters until reached desired length\n",
    "    while len(generated_text) < length:\n",
    "        # Get the last two characters from the current text\n",
    "        last_two = generated_text[-2:]\n",
    "\n",
    "        # Find all trigrams starting with those two characters\n",
    "        possible_trigrams = {trigram: count for trigram, count in trigram_model.items() if trigram.startswith(last_two)}\n",
    "\n",
    "        if not possible_trigrams:\n",
    "            # In case there are no trigrams starting with the last two characters, stop generating\n",
    "            print(f\"Warning: No trigrams found for the pair '{last_two}'.\")\n",
    "            break\n",
    "\n",
    "        # Separate the third letter and their respective counts\n",
    "        letters = [trigram[2] for trigram in possible_trigrams.keys()]\n",
    "        counts = list(possible_trigrams.values())\n",
    "\n",
    "        next_char = random.choices(letters, weights=counts, k=1)[0]\n",
    "\n",
    "        generated_text += next_char\n",
    "    # Add line breaks at the specified line length (default 80 characters per line)\n",
    "    formatted_text = '\\n'.join([generated_text[i:i+line_length] for i in range(0, len(generated_text), line_length)])\n",
    "\n",
    "    return formatted_text\n",
    "\n",
    "# Generate the text and print possible trigrams for debugging (set debug=True)\n",
    "generated_text = generate_text(combined_trigram_model, length=10000, line_length=80)\n",
    "\n",
    "\n",
    "# Display the first 500 characters of the generated text\n",
    "print(f\"\\nGenerated text (first 500 characters):\\n{generated_text[:500]}\")\n",
    "print(\"\\n\\n\")\n",
    "print_trigram_possibilities(combined_trigram_model, \"TH\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3. Analyze your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `load_words` Function\n",
    "\n",
    "The `load_words` function is designed to load a set of valid English words from a specified file. It reads each line from the file, strips any whitespace (including newline characters) from the ends, and converts each word to lowercase to ensure uniformity. The function returns a set of these valid words, which can be used for various text analysis tasks, such as validating the words in generated text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_words(file_path):\n",
    "    \"\"\"\n",
    "    Load a set of valid words from a file.\n",
    "\n",
    "    This function reads a file located at the specified file path, where each line\n",
    "    in the file represents a word. It strips any whitespace from the ends of each\n",
    "    line and converts each word to lowercase to ensure uniformity. The words are\n",
    "    stored in a set to eliminate duplicates and allow for efficient membership testing.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the file containing the words.\n",
    "\n",
    "    Returns:\n",
    "        set: A set of valid words loaded from the file, all in lowercase.\n",
    "    \"\"\"\n",
    "    ''''''\n",
    "     # Open the file located at 'file_path' in read mode\n",
    "    with open(file_path, 'r') as f:\n",
    "        # Use a set comprehension to read each line from the file,\n",
    "        # strip any whitespace (including newline characters) from the ends,\n",
    "        # and convert each word to lowercase to ensure uniformity.\n",
    "        valid_words = {line.strip().lower() for line in f}\n",
    "    # Return the set of valid words loaded from the file\n",
    "    return valid_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `extract_words` function\n",
    "This function removes punctuation, converts the text to lowercase, and splits it into individual words. \n",
    "It is used to preprocess text for further analysis, ensuring consistency in word extraction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_words(text):\n",
    "    \"\"\"\n",
    "    Extracts words from a given text by splitting on non-alphabetic characters.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The input text to extract words from.\n",
    "        \n",
    "    Returns:\n",
    "        list: A list of extracted words from the text.\n",
    "    \"\"\"\n",
    "\n",
    "    # Remove punctuation and convert to lowercase\n",
    "    translator = str.maketrans('','',string.punctuation)\n",
    "    clean_text = text.translate(translator).lower()\n",
    "\n",
    "    # Split by spaces to get words\n",
    "    words = clean_text.split()\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `calculate_word_percentage` Function\n",
    "\n",
    "The `calculate_word_percentage` function is designed to evaluate the coherence of the generated text by calculating the percentage of valid English words it contains. This function performs the following steps:\n",
    "\n",
    "1. **Extract Words from Generated Text**:\n",
    "    - The function uses the `extract_words` function to preprocess the generated text by removing punctuation, converting it to lowercase, and splitting it into individual words.\n",
    "\n",
    "2. **Count Valid Words**:\n",
    "    - Each extracted word is checked against a set of valid English words (`valid_words`).\n",
    "    - The function counts how many of the extracted words are valid English words.\n",
    "\n",
    "3. **Calculate Percentage**:\n",
    "    - The percentage of valid English words is calculated by dividing the count of valid words by the total number of extracted words.\n",
    "    - The function returns the percentage of valid words, the count of valid words, and the total number of words.\n",
    "\n",
    "This function helps in assessing the quality of the generated text by providing a quantitative measure of its validity based on the presence of recognizable English words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_word_percentage(generated_text, valid_words):\n",
    "    \"\"\"\n",
    "    Calculates the percentage of valid English words in the generated text.\n",
    "    \n",
    "    Args:\n",
    "        generated_text (str): The generated text from Task 2.\n",
    "        valid_words (set): A set of valid English words.\n",
    "        \n",
    "    Returns:\n",
    "        float: The percentage of valid words in the text.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract words from the generated text\n",
    "    words = extract_words(generated_text)\n",
    "\n",
    "    # Count the valid words\n",
    "    valid_word_count = sum(1 for word in words if word in valid_words)\n",
    "\n",
    "    # Calculate the percentage of valid words there\n",
    "    total_words = len(words)\n",
    "    percentage = (valid_word_count / total_words) * 100 if total_words > 0 else 0\n",
    "\n",
    "    return percentage, valid_word_count, total_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `load_words` function\n",
    "\n",
    "The function performs the following steps:\n",
    "\n",
    "1. **Load Valid English Words**:\n",
    "    - Loads a list of valid English words from `data/words.txt` using the `load_words` function.\n",
    "\n",
    "2. **Generate Text**:\n",
    "    - Utilizes the text generated in Task 2 by calling the `generate_text` function with the combined trigram model and specifying a length of 10,000 characters.\n",
    "\n",
    "3. **Calculate Percentage of Valid English Words**:\n",
    "    - Calculates the percentage of valid English words in the generated text using the `calculate_word_percentage` function.\n",
    "\n",
    "4. **Print Results**:\n",
    "    - Prints the total number of valid English words, the total number of words generated, and the percentage of valid words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid words: 689 / 1881\n",
      "Percentage of valid English words: 36.63%\n"
     ]
    }
   ],
   "source": [
    "# Load the valid english words from words.txt\n",
    "valid_words = load_words('data/words.txt')\n",
    "\n",
    "# Use the generated text from Task 2\n",
    "generated_text = generate_text(combined_trigram_model, length=10000)\n",
    "\n",
    "# Calculate the percentage of valid English words\n",
    "percentage, valid_word_count, total_words = calculate_word_percentage(generated_text, valid_words)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Valid words: {valid_word_count} / {total_words}\")\n",
    "print(f\"Percentage of valid English words: {percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Export your model as JSON\n",
    "\n",
    "In this task, we will export the combined trigram model to a JSON file. The combined trigram model is stored in the variable `combined_trigram_model`, which is a `defaultdict` containing the counts of trigrams. The output file will be named `trigrams.json`.\n",
    "\n",
    "The following steps will be performed:\n",
    "1. Define the `export_trigram_model` function to export the trigram model to a JSON file.\n",
    "2. Specify the name of the output file.\n",
    "3. Call the function to export the trigram model.\n",
    "4. Print a confirmation message indicating that the trigram model has been exported.\n",
    "\n",
    "The `export_trigram_model` function is defined as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_trigram_model(trigram_model, output_file):\n",
    "    \"\"\"\n",
    "    Exports the trigram model to a JSON file.\n",
    "    \n",
    "    Args:\n",
    "        trigram_model (dict): The trigram model containing counts of trigrams.\n",
    "        output_file (str): The path to the output JSON file.\n",
    "    \"\"\"\n",
    "\n",
    "    # Open the specified output file in write mode\n",
    "    with open(output_file, 'w') as f:\n",
    "        # Use json.dump() to write the trigram model to the file\n",
    "        json.dump(trigram_model, f, indent=4) # indent = 4, this is for nice printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigram model has been exported to trigrams.json\n"
     ]
    }
   ],
   "source": [
    "# Specify the name of the output file where the trigram model will be saved\n",
    "output_file = 'trigrams.json'\n",
    "# Call the function to export the trigram model to a JSON file\n",
    "# 'combined_trigram_model' is the dictionary containing the trigrams and their counts\n",
    "export_trigram_model(combined_trigram_model,output_file)\n",
    "# Print the results\n",
    "print(f\"Trigram model has been exported to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "In this Jupyter Notebook, we successfully implemented a trigram-based model for text analysis and generation. The workflow included the following tasks:\n",
    "\n",
    "1. **Cleaning and Preprocessing of Text Data**:\n",
    "    - Loaded and cleaned text data from Project Gutenberg, removing unwanted characters and normalizing the text to prepare it for analysis.\n",
    "\n",
    "2. **Building a Trigram Model**:\n",
    "    - Constructed a trigram model to capture patterns of three consecutive characters in the cleaned text.\n",
    "    - Counted the occurrences of each trigram to understand the frequency of character sequences.\n",
    "\n",
    "3. **Generating Text Using the Trigram Model**:\n",
    "    - Used the trigram model to generate new text that mimics the style and structure of the original text.\n",
    "    - Implemented a function to produce a specified length of text based on the trigram probabilities.\n",
    "\n",
    "4. **Analyzing the Validity of Generated Text**:\n",
    "    - Evaluated the generated text by calculating the percentage of valid English words.\n",
    "    - Compared the generated text to a dictionary of valid words to assess its coherence.\n",
    "    - Generated text contained approximately 37% valid English words.\n",
    "\n",
    "5. **Exporting the Trigram Model in JSON Format**:\n",
    "    - Saved the trigram model to a JSON file for future use and sharing.\n",
    "    - This ensures that the model is easily accessible and reusable.\n",
    "\n",
    "Overall, this notebook provided a comprehensive guide to creating and utilizing a trigram-based model for text analysis and generation, offering insights into the patterns and structures of English text. The generated text, while not perfect, demonstrated the potential of trigram models in capturing and replicating language patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tests for Task 1\n",
    "Using Python's `unittest` library, we will test the functions implemented in Task 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestCleanText(unittest.TestCase):\n",
    "    def test_clean_text(self):\n",
    "        self.assertEqual(clean_text(\"Hello, World!\"), \"HELLO WORLD\")\n",
    "        self.assertEqual(clean_text(\"This   is\\na test.\"), \"THIS IS A TEST.\")\n",
    "        self.assertEqual(clean_text(\"1234!@#$%^&*()\"), \"\")\n",
    "        self.assertEqual(clean_text(\"The end.\"), \"THE END.\")\n",
    "        self.assertEqual(clean_text(\"\"), \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestBuildTrigramModel(unittest.TestCase):\n",
    "    def test_build_trigram_model(self):\n",
    "        # Test with a simple text\n",
    "        text = \"HELLO WORLD\"\n",
    "        expected_output = {\n",
    "            'HEL': 1,\n",
    "            'ELL': 1,\n",
    "            'LLO': 1,\n",
    "            'LO ': 1,\n",
    "            'O W': 1,\n",
    "            ' WO': 1,\n",
    "            'WOR': 1,\n",
    "            'ORL': 1,\n",
    "            'RLD': 1\n",
    "        }\n",
    "        self.assertEqual(build_trigram_model(text), expected_output)\n",
    "\n",
    "        # Test with repeated trigrams\n",
    "        text = \"AAA\"\n",
    "        expected_output = {\n",
    "            'AAA': 1\n",
    "        }\n",
    "        self.assertEqual(build_trigram_model(text), expected_output)\n",
    "\n",
    "        # Test with no trigrams\n",
    "        text = \"AB\"\n",
    "        expected_output = {}\n",
    "        self.assertEqual(build_trigram_model(text), expected_output)\n",
    "\n",
    "        # Test with empty string\n",
    "        text = \"\"\n",
    "        expected_output = {}\n",
    "        self.assertEqual(build_trigram_model(text), expected_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "class TestProcessFile(unittest.TestCase):\n",
    "    def test_process_file(self):\n",
    "        # Create a sample text with Project Gutenberg markers\n",
    "        sample_text = \"\"\"\n",
    "        *** START OF THIS PROJECT GUTENBERG EBOOK SAMPLE ***\n",
    "        This is a sample text for testing.\n",
    "        It includes multiple lines and some punctuation!\n",
    "        *** END OF THIS PROJECT GUTENBERG EBOOK SAMPLE ***\n",
    "        \"\"\"\n",
    "        # Write the sample text to a temporary file\n",
    "        with open('sample.txt', 'w', encoding='utf-8') as f:\n",
    "            f.write(sample_text)\n",
    "        \n",
    "        # Process the file\n",
    "        cleaned_text = process_file('sample.txt')\n",
    "        \n",
    "        # Expected cleaned text\n",
    "        expected_cleaned_text = \"THIS IS A SAMPLE TEXT FOR TESTING. IT INCLUDES MULTIPLE LINES AND SOME PUNCTUATION\"\n",
    "        \n",
    "        # Check if the cleaned text matches the expected output\n",
    "        self.assertEqual(cleaned_text, expected_cleaned_text)\n",
    "        \n",
    "        # Remove the temporary file\n",
    "        os.remove('sample.txt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestProcessMultipleFiles(unittest.TestCase):\n",
    "    def test_process_multiple_files(self):\n",
    "        # Create mock Gutenberg files\n",
    "        with open(\"file1.txt\", \"w\") as file1:\n",
    "            file1.write(\n",
    "                \"*** START OF THE PROJECT GUTENBERG EBOOK TEST ***\\n\"\n",
    "                \"HELLO WORLD\\n\"\n",
    "                \"*** END OF THE PROJECT GUTENBERG EBOOK TEST ***\"\n",
    "            )\n",
    "        with open(\"file2.txt\", \"w\") as file2:\n",
    "            file2.write(\n",
    "                \"*** START OF THE PROJECT GUTENBERG EBOOK TEST ***\\n\"\n",
    "                \"WORLD PEACE\\n\"\n",
    "                \"*** END OF THE PROJECT GUTENBERG EBOOK TEST ***\"\n",
    "            )\n",
    "        \n",
    "        combined_model = process_multiple_files([\"file1.txt\", \"file2.txt\"])\n",
    "\n",
    "        combined_model = dict(combined_model)\n",
    "\n",
    "        \n",
    "        expected = {\n",
    "            \"HEL\": 1,\n",
    "            \"ELL\": 1,\n",
    "            \"LLO\": 1,\n",
    "            \"LO \": 1,\n",
    "            \"O W\": 1,\n",
    "            \" WO\": 1,\n",
    "            \"WOR\": 2,\n",
    "            \"ORL\": 2,\n",
    "            \"RLD\": 2,\n",
    "            \"LD \": 1,\n",
    "            \"D P\": 1,\n",
    "            \" PE\": 1,\n",
    "            \"PEA\": 1,\n",
    "            \"EAC\": 1,\n",
    "            \"ACE\": 1\n",
    "        }\n",
    "        self.assertEqual(combined_model, expected)\n",
    "        os.remove(\"file1.txt\")\n",
    "        os.remove(\"file2.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tests for Task 2\n",
    "Using Python's `unittest` library, we will test the functions implemented in Task 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mocked trigram model for testing purposes\n",
    "TEST_TRIGRAM_MODEL = {\n",
    "    \"THA\": 5, \"THE\": 10, \"TH \": 3, \"HEA\": 4, \"HEL\": 5, \"HE \": 3,\n",
    "    \"ELL\": 6, \"LO \": 4, \"O W\": 4, \"WOR\": 6, \"ORL\": 5, \"RLD\": 5,\n",
    "    \"LD \": 3, \"D C\": 3, \" CE\": 2, \"CEA\": 2, \"EAC\": 3, \"ACE\": 3,\n",
    "    \"E L\": 4, \"LLO\": 3, \"LO \": 2, \"O T\": 4, \" TO\": 5, \"TO \": 3,\n",
    "    \"A T\": 3, \"T H\": 3, \"HAT\": 4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestPrintTrigramPossibilities(unittest.TestCase):\n",
    "    @patch('sys.stdout', new_callable=StringIO)\n",
    "    def test_print_trigram_possibilities(self, mock_stdout):\n",
    "        \"\"\"\n",
    "        Test that print_trigram_possibilities correctly outputs probabilities \n",
    "        based on the updated TEST_TRIGRAM_MODEL.\n",
    "        \"\"\"\n",
    "        # Use the updated TEST_TRIGRAM_MODEL\n",
    "        trigram_model = TEST_TRIGRAM_MODEL\n",
    "\n",
    "         # Call the function\n",
    "        print_trigram_possibilities(trigram_model, \"TH\")\n",
    "\n",
    "        # Expected output with corrected probabilities\n",
    "        expected_output = (\n",
    "            \"Possible next characters after 'TH':\\n\"\n",
    "            \"THA: appeared 5 times, probability = 0.2778\\n\"\n",
    "            \"THE: appeared 10 times, probability = 0.5556\\n\"\n",
    "            \"TH : appeared 3 times, probability = 0.1667\\n\"\n",
    "            \"Total occurrences; 18\\n\\n\"\n",
    "        )\n",
    "\n",
    "        # Compare the actual output to the expected output\n",
    "        self.assertEqual(mock_stdout.getvalue(), expected_output)\n",
    "        \n",
    "    @patch('sys.stdout', new_callable=StringIO)\n",
    "    def test_print_trigram_possibilities_no_match(self, mock_stdout):\n",
    "        \"\"\"\n",
    "        Test print_trigram_possibilities when there are no matching trigrams.\n",
    "        \"\"\"\n",
    "        # Use the updated TEST_TRIGRAM_MODEL\n",
    "        trigram_model = TEST_TRIGRAM_MODEL\n",
    "\n",
    "        # Call the function with a non-existent pair\n",
    "        print_trigram_possibilities(trigram_model, \"ZZ\")\n",
    "\n",
    "        # Expected output when no matching trigrams are found\n",
    "        expected_output = \"No trigrams found starting with 'ZZ'.\\n\"\n",
    "\n",
    "        # Compare the output\n",
    "        self.assertEqual(mock_stdout.getvalue(), expected_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for print_trigram_possibilities when no matching trigrams are found\n",
    "class TestPrintTrigramPossibilitiesNoMatch(unittest.TestCase):\n",
    "    @patch('sys.stdout', new_callable=StringIO)\n",
    "    def test_print_trigram_possibilities_no_match(self, mock_stdout):\n",
    "        \"\"\"\n",
    "        Test print_trigram_possibilities with no matching trigrams.\n",
    "        \"\"\"\n",
    "        print_trigram_possibilities(TEST_TRIGRAM_MODEL, \"ZZ\")\n",
    "        \n",
    "        expected_output = \"No trigrams found starting with 'ZZ'.\\n\"\n",
    "        self.assertEqual(mock_stdout.getvalue(), expected_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestGenerateTextLength(unittest.TestCase):\n",
    "    def test_generate_text_length(self):\n",
    "        \"\"\"\n",
    "        Test that generate_text generates the correct text length.\n",
    "        \"\"\"\n",
    "        random.seed(42)  # For deterministic output\n",
    "        generated = generate_text(TEST_TRIGRAM_MODEL, length=50, line_length=20)\n",
    "\n",
    "        # Check that the text starts with \"TH\"\n",
    "        self.assertTrue(generated.startswith(\"TH\"))\n",
    "\n",
    "        # Check that the total length (ignoring line breaks) matches 50\n",
    "        total_chars = len(generated.replace(\"\\n\", \"\"))\n",
    "        self.assertEqual(total_chars, 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for generate_text to ensure correct line formatting\n",
    "class TestGenerateTextLineBreaks(unittest.TestCase):\n",
    "    def test_generate_text_line_breaks(self):\n",
    "        \"\"\"\n",
    "        Test that generate_text formats text with correct line breaks.\n",
    "        \"\"\"\n",
    "        random.seed(42)  # For consistent results\n",
    "        generated = generate_text(TEST_TRIGRAM_MODEL, length=100, line_length=20)\n",
    "\n",
    "        # Split the generated text by lines\n",
    "        lines = generated.split(\"\\n\")\n",
    "\n",
    "        # Check that all lines except the last one have 20 characters\n",
    "        for line in lines[:-1]:\n",
    "            self.assertEqual(len(line), 20)\n",
    "\n",
    "        # Check that the last line is not longer than 20 characters\n",
    "        self.assertTrue(len(lines[-1]) <= 20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tests for Task 3\n",
    "Using Python's `unittest` library, we will test the functions implemented in Task 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestLoadWords(unittest.TestCase):\n",
    "    def test_load_words(self):\n",
    "        # Create a temporary file with sample words\n",
    "        sample_words = \"Hello\\nWorld\\nTEST\\nSample\\n\"\n",
    "        with open(\"temp_words.txt\", \"w\") as f:\n",
    "            f.write(sample_words)\n",
    "\n",
    "        # Run the function and compare the output\n",
    "        result = load_words(\"temp_words.txt\")\n",
    "        expected = {\"hello\", \"world\", \"test\", \"sample\"}\n",
    "        self.assertEqual(result, expected)\n",
    "\n",
    "        # Clean up\n",
    "        os.remove(\"temp_words.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestExtractWords(unittest.TestCase):\n",
    "    def test_extract_words(self):\n",
    "        text = \"Hello, World! This is a test.\"\n",
    "        result = extract_words(text)\n",
    "        expected = [\"hello\", \"world\", \"this\", \"is\", \"a\", \"test\"]\n",
    "        self.assertEqual(result, expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_build_trigram_model (__main__.TestBuildTrigramModel.test_build_trigram_model) ... ok\n",
      "test_clean_text (__main__.TestCleanText.test_clean_text) ... ok\n",
      "test_extract_words (__main__.TestExtractWords.test_extract_words) ... ok\n",
      "test_generate_text_length (__main__.TestGenerateTextLength.test_generate_text_length)\n",
      "Test that generate_text generates the correct text length. ... ok\n",
      "test_generate_text_line_breaks (__main__.TestGenerateTextLineBreaks.test_generate_text_line_breaks)\n",
      "Test that generate_text formats text with correct line breaks. ... ok\n",
      "test_load_words (__main__.TestLoadWords.test_load_words) ... ok\n",
      "test_print_trigram_possibilities (__main__.TestPrintTrigramPossibilities.test_print_trigram_possibilities)\n",
      "Test that print_trigram_possibilities correctly outputs probabilities ... ok\n",
      "test_print_trigram_possibilities_no_match (__main__.TestPrintTrigramPossibilities.test_print_trigram_possibilities_no_match)\n",
      "Test print_trigram_possibilities when there are no matching trigrams. ... ok\n",
      "test_print_trigram_possibilities_no_match (__main__.TestPrintTrigramPossibilitiesNoMatch.test_print_trigram_possibilities_no_match)\n",
      "Test print_trigram_possibilities with no matching trigrams. ... ok\n",
      "test_process_file (__main__.TestProcessFile.test_process_file) ... ok\n",
      "test_process_multiple_files (__main__.TestProcessMultipleFiles.test_process_multiple_files) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 11 tests in 0.067s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x1fd7b18b830>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
