{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 1: Load and Clean the Text\n",
    "def clean_text(text):\n",
    "    # Replace newlines with spaces.\n",
    "    text = text.replace('\\n', ' ')\n",
    "                        \n",
    "    # Remove non-alphabetic characters. Keep letters, spaces and full stops\n",
    "    cleaned = re.sub(r'[^A-Z\\s.]','', text.upper())\n",
    "\n",
    "    # Replace multiple spaces with a single space\n",
    "    cleaned = re.sub(r'\\s+',' ',cleaned)\n",
    "\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load in Text files and clean them\n",
    "def process_file(file_path):\n",
    "    # Open the file located at 'file_path' in read mode with utf-8 encoding\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        # Read the entire content of the file into the variable 'text'\n",
    "        text = f.read()\n",
    "\n",
    "    # Search for the start marker indicating the beginning\n",
    "    start_marker = re.search(r\"\\*\\*\\* START OF (THE|THIS) PROJECT GUTENBERG EBOOK.*\\*\\*\\*\", text)\n",
    "    # Search for the end marker indicating the end of the content\n",
    "    end_marker = re.search(r\"\\*\\*\\* END OF (THE|THIS) PROJECT GUTENBERG EBOOK.*\\*\\*\\*\", text)\n",
    "\n",
    "    # If both the start and end markers are found, extract the text between them\n",
    "    if start_marker and end_marker:\n",
    "        text = text[start_marker.end():end_marker.start()]\n",
    "    else:\n",
    "        # If markers are not found, print a warning message\n",
    "        print(\"Warning: Could not find standard Project Gutenberg markers.\")\n",
    "\n",
    "    # Clean the text\n",
    "    return clean_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ********** Example of how to use the function on a single file:  *********************\n",
    "# Load and clean the text from a file (in this case, 'Frankenstein')\n",
    "# cleaned_text = process_file('gutenbergTexts/frankenstein.txt')\n",
    "\n",
    "# Display the first 500 characters of Frankenstein\n",
    "# print(cleaned_text[:500])  \n",
    "\n",
    "# Function to build a trigram model from the cleaned text\n",
    "def build_trigram_model(cleaned_text):\n",
    "    # Initialize a dictionary to count the occurences of each trigram\n",
    "    trigram_counts = defaultdict(int)\n",
    "\n",
    "    # Loop through the text and the create trigrams\n",
    "    # A trigram consists of 3 consecutive characters, so we iterate over the text, \n",
    "    # stopping 2 characters before the end to avoid index out-of-range errors\n",
    "    for i in range(len(cleaned_text) -2):\n",
    "        # Extract the current trigram (3-character sequence)\n",
    "        trigram = cleaned_text[i:i+3]\n",
    "        # Increment the count of this trigram in the dictionary\n",
    "        trigram_counts[trigram] += 1\n",
    "\n",
    "    # Return the dictionary of trigram counts\n",
    "    return trigram_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process multiple text files and build a combined trigram model\n",
    "def process_multiple_files(file_paths):\n",
    "    # Initialize a dictionary to store trigram counts across all files\n",
    "    combined_trigram_counts = defaultdict(int)\n",
    "\n",
    "    # Loop through the list of file paths\n",
    "    for file_path in file_paths:\n",
    "        # Process/Clean the file\n",
    "        cleaned_text = process_file(file_path)\n",
    "\n",
    "        # Build trigram model for the current file\n",
    "        trigram_counts = build_trigram_model(cleaned_text)\n",
    "\n",
    "        # Merge the trigram counts from this file into the combined count\n",
    "        for trigram, count in trigram_counts.items():\n",
    "            combined_trigram_counts[trigram] += count\n",
    "        \n",
    "    # Return the combined trigram counts from all files\n",
    "    return combined_trigram_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' LE': 2789, 'LET': 1288, 'ETT': 997, 'TTE': 2141, 'TER': 7254, 'ER ': 17193, 'R T': 4524, ' TO': 16087, 'TO ': 14617, 'O M': 1842, ' MR': 1372, 'MRS': 374, 'RS.': 716, 'S. ': 3141, '. S': 1466, ' SA': 3993, 'SAV': 180, 'AVI': 512, 'VIL': 479, 'ILL': 3706, 'LLE': 1195, 'LE ': 6435, 'E E': 2250, ' EN': 2286, 'ENG': 723, 'NGL': 984, 'GLA': 350, 'LAN': 1307, 'AND': 19336, 'ND.': 311, 'D. ': 1902, ' ST': 5071, 'ST.': 309, 'T. ': 2435, '. P': 340, ' PE': 2722, 'PET': 180, 'ETE': 587, 'ERS': 3578, 'RSB': 3, 'SBU': 18, 'BUR': 315, 'URG': 149, 'RGH': 64, 'GH ': 1784, 'H D': 294, ' DE': 4535, 'DEC': 579, 'EC.': 3, 'C. ': 70, '. T': 3299, ' TH': 55432, 'TH ': 7714, 'H .': 11, ' . ': 311, '. Y': 568, ' YO': 5124, 'YOU': 5050, 'OU ': 3929, 'U W': 495, ' WI': 8644, 'WIL': 1842, 'LL ': 7835, 'L R': 313, ' RE': 6192, 'REJ': 103, 'EJO': 52, 'JOI': 192, 'OIC': 276, 'ICE': 1039, 'CE ': 4594, 'E T': 10499, 'O H': 1994, ' HE': 13123, 'HEA': 2504, 'EAR': 4471, 'AR ': 2179, 'THA': 8516, 'HAT': 9320, 'AT ': 12970, 'T N': 1158, ' NO': 8420, 'NO ': 1598, 'O D': 914, ' DI': 3600, 'DIS': 1540, 'ISA': 220, 'SAS': 35, 'AST': 2488, 'STE': 3085, 'R H': 2077, ' HA': 10254, 'HAS': 1089, 'AS ': 11125, 'S A': 7602, ' AC': 1208, 'ACC': 641, 'CCO': 386, 'COM': 2658, 'OMP': 944}\n"
     ]
    }
   ],
   "source": [
    "# List all file paths for 5 different books from Project Gutenberg\n",
    "file_paths = [\n",
    "    'gutenbergTexts/frankenstein.txt',\n",
    "    'gutenbergTexts/mobydick.txt',\n",
    "    'gutenbergTexts/prideAndPrejudice.txt',\n",
    "    'gutenbergTexts/romeoAndJuliet.txt',\n",
    "    'gutenbergTexts/scarletLetter.txt'\n",
    "]\n",
    "\n",
    "# Process all the files and build a combined trigram model from the listed file paths\n",
    "combined_trigram_model = process_multiple_files(file_paths)\n",
    "\n",
    "# Display the first 10 trigram counts from the combined trigram model\n",
    "print(dict(list(combined_trigram_model.items())[:100])) # Convert to a list of tuples and display the first 10 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2: Third-order letter approximation generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(trigram_model, length = 10000):\n",
    "    \"\"\"\n",
    "    Generates a string of the specified length using a trigram model.\n",
    "    \n",
    "    Args:\n",
    "        trigram_model (dict): The trigram model containing counts of trigrams.\n",
    "        length (int): The number of characters to generate (default is 10,000).\n",
    "        \n",
    "    Returns:\n",
    "        str: The generated string of characters.\n",
    "    \"\"\"\n",
    "    # Start with the string \"TH\" \n",
    "    generated_text = \"TH\"\n",
    "\n",
    "    # Cntinue generating characters until reached desired length\n",
    "    while len(generate_text) < length:\n",
    "        # Get the last two characters from the current text\n",
    "        last_two = generate_text[-2:]\n",
    "\n",
    "        # Find all trigrams starting with those two characters\n",
    "        possible_trigrams = {trigram: count for trigram, count in trigram_model.items() if trigram.startswith(last_two)}\n",
    "\n",
    "        if not possible_trigrams:\n",
    "            # In case there are no trigrams starting with the last two characters, stop generating\n",
    "            print(f\"Warning: No trigrams found for the pair '{last_two}'.\")\n",
    "            break\n",
    "\n",
    "        # Seperate the third letter and their respective counts\n",
    "        letters = [trigram[2] for trigram in possible_trigrams.keys()]\n",
    "        counts = list(possible_trigrams.values())\n",
    "\n",
    "        next_char = random.choices(letters, weights=counts, k=1)[0]\n",
    "\n",
    "        generate_text += next_char\n",
    "    return generate_text\n",
    "\n",
    "generate_text = generate_text(combined_trigram_model, length = 10000)\n",
    "\n",
    "print(generate_text[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
