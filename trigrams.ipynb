{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trigram-Based Model for Text Analysis and Generation\n",
    "\n",
    "This Jupyter Notebook demonstrates the process of building and utilizing a trigram-based model for text analysis and generation. The workflow includes the following steps:\n",
    "\n",
    "- **Cleaning and Preprocessing of Text Data from Project Gutenberg**:\n",
    "    - Load and clean text data from Project Gutenberg to prepare it for analysis.\n",
    "    - Remove unwanted characters and normalize the text.\n",
    "\n",
    "- **Building a Trigram Model for Patterns in English**:\n",
    "    - Construct a trigram model to capture patterns of three consecutive characters in the cleaned text.\n",
    "    - Count the occurrences of each trigram to understand the frequency of character sequences.\n",
    "\n",
    "- **Generating Text Using the Trigram Model**:\n",
    "    - Use the trigram model to generate new text that mimics the style and structure of the original text.\n",
    "    - Implement a function to produce a specified length of text based on the trigram probabilities.\n",
    "\n",
    "- **Analyzing the Validity of Generated Text**:\n",
    "    - Evaluate the generated text by calculating the percentage of valid English words.\n",
    "    - Compare the generated text to a dictionary of valid words to assess its coherence.\n",
    "\n",
    "- **Exporting the Trigram Model in JSON Format**:\n",
    "    - Save the trigram model to a JSON file for future use and sharing.\n",
    "    - Ensure the model is easily accessible and reusable.\n",
    "\n",
    "This notebook provides a comprehensive guide to creating and utilizing a trigram-based model for text analysis and generation, offering insights into the patterns and structures of English text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleans the input text by performing the following operations:\n",
    "1. Replaces newline characters with spaces.\n",
    "2. Removes non-alphabetic characters, keeping only uppercase letters, spaces, and full stops.\n",
    "3. Replaces multiple consecutive spaces with a single space.\n",
    "\n",
    "Args:\n",
    "    text (str): The input text to be cleaned.\n",
    "\n",
    "Returns:\n",
    "    str: The cleaned text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 1: Load and Clean the Text\n",
    "def clean_text(text):\n",
    "    # Replace newlines with spaces.\n",
    "    text = text.replace('\\n', ' ')\n",
    "                        \n",
    "    # Remove non-alphabetic characters. Keep letters, spaces and full stops\n",
    "    cleaned = re.sub(r'[^A-Z\\s.]','', text.upper())\n",
    "\n",
    "    # Replace multiple spaces with a single space\n",
    "    cleaned = re.sub(r'\\s+',' ',cleaned)\n",
    "\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process a text file by extracting and cleaning its content.\n",
    "\n",
    "This function reads the content of a text file located at the specified file path,\n",
    "searches for specific start and end markers indicating the beginning and end of the\n",
    "main content (typically used in Project Gutenberg eBooks), and extracts the text\n",
    "between these markers. If the markers are not found, a warning message is printed.\n",
    "The extracted text is then cleaned using the `clean_text` function.\n",
    "\n",
    "Args:\n",
    "    file_path (str): The path to the text file to be processed.\n",
    "\n",
    "Returns:\n",
    "    str: The cleaned text extracted from the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load in Text files and clean them\n",
    "def process_file(file_path):\n",
    "    # Open the file located at 'file_path' in read mode with utf-8 encoding\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        # Read the entire content of the file into the variable 'text'\n",
    "        text = f.read()\n",
    "\n",
    "    # Search for the start marker indicating the beginning\n",
    "    start_marker = re.search(r\"\\*\\*\\* START OF (THE|THIS) PROJECT GUTENBERG EBOOK.*\\*\\*\\*\", text)\n",
    "    # Search for the end marker indicating the end of the content\n",
    "    end_marker = re.search(r\"\\*\\*\\* END OF (THE|THIS) PROJECT GUTENBERG EBOOK.*\\*\\*\\*\", text)\n",
    "\n",
    "    # If both the start and end markers are found, extract the text between them\n",
    "    if start_marker and end_marker:\n",
    "        text = text[start_marker.end():end_marker.start()]\n",
    "    else:\n",
    "        # If markers are not found, print a warning message\n",
    "        print(\"Warning: Could not find standard Project Gutenberg markers.\")\n",
    "\n",
    "    # Clean the text\n",
    "    return clean_text(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of How to Use the `process_file` Function\n",
    "\n",
    "The `process_file` function is designed to load and clean the text from a specified file. Below is an example of how to use this function on a single file:\n",
    "\n",
    "1. **Load and Clean the Text**:\n",
    "    - The function reads the content of the file located at the specified path.\n",
    "    - It searches for specific start and end markers to extract the main content.\n",
    "    - The extracted text is then cleaned using the `clean_text` function.\n",
    "\n",
    "2. **Example Usage**:\n",
    "    - In this example, the text is loaded and cleaned from the file `frankenstein.txt` located in the `gutenbergtexts` directory.\n",
    "    - The first 500 characters of the cleaned text are displayed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ********** Example of how to use the function on a single file:  *********************\n",
    "\n",
    "# Load and clean the text from a file (in this case, 'Frankenstein')\n",
    "# cleaned_text = process_file('gutenbergtexts/frankenstein.txt')\n",
    "\n",
    "# Display the first 500 characters of Frankenstein\n",
    "# print(cleaned_text[:500])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of How to Use the `build_trigram_model` Function\n",
    "\n",
    "The `build_trigram_model` function is designed to build a trigram model from cleaned text. Below is an example of how to use this function on the cleaned text from the file `frankenstein.txt`:\n",
    "\n",
    "1. **Build the Trigram Model**:\n",
    "    - The function takes the cleaned text as input.\n",
    "    - It constructs a trigram model by counting the occurrences of each trigram (three consecutive characters).\n",
    "\n",
    "2. **Example Usage**:\n",
    "    - In this example, the trigram model is built from the cleaned text of `frankenstein.txt`.\n",
    "    - The first 10 trigram counts from the model are displayed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build a trigram model from the cleaned text\n",
    "def build_trigram_model(cleaned_text):\n",
    "    # Initialize a dictionary to count the occurrences of each trigram\n",
    "    trigram_counts = defaultdict(int)\n",
    "\n",
    "    # Loop through the text and the create trigrams\n",
    "    # A trigram consists of 3 consecutive characters, so we iterate over the text, \n",
    "    # stopping 2 characters before the end to avoid index out-of-range errors\n",
    "    for i in range(len(cleaned_text) -2):\n",
    "        # Extract the current trigram (3-character sequence)\n",
    "        trigram = cleaned_text[i:i+3]\n",
    "        # Increment the count of this trigram in the dictionary\n",
    "        trigram_counts[trigram] += 1\n",
    "\n",
    "    # Return the dictionary of trigram counts\n",
    "    return trigram_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to process multiple text files and build a combined trigram model\n",
    "\n",
    "Description\n",
    "This function takes a list of file paths, processes each file to clean the text, builds a trigram model for each file, and then combines the trigram counts from all files into a single dictionary. The combined trigram counts are returned as the output.\n",
    "\n",
    "Parameters\n",
    "- `file_paths` (list of str): A list of file paths to be processed.\n",
    "\n",
    "Returns\n",
    "- `combined_trigram_counts` (defaultdict of int): A dictionary containing the combined trigram counts from all the processed files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process multiple text files and build a combined trigram model\n",
    "def process_multiple_files(file_paths):\n",
    "    # Initialize a dictionary to store trigram counts across all files\n",
    "    combined_trigram_counts = defaultdict(int)\n",
    "\n",
    "    # Loop through the list of file paths\n",
    "    for file_path in file_paths:\n",
    "        # Process/Clean the file\n",
    "        cleaned_text = process_file(file_path)\n",
    "\n",
    "        # Build trigram model for the current file\n",
    "        trigram_counts = build_trigram_model(cleaned_text)\n",
    "\n",
    "        # Merge the trigram counts from this file into the combined count\n",
    "        for trigram, count in trigram_counts.items():\n",
    "            combined_trigram_counts[trigram] += count\n",
    "        \n",
    "    # Return the combined trigram counts from all files\n",
    "    return combined_trigram_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "List all file paths for 5 different books from Project Gutenberg and process them to build a combined trigram model.\n",
    "\n",
    "The function performs the following steps:\n",
    "1. Lists the file paths for five books from Project Gutenberg.\n",
    "2. Processes all the files and builds a combined trigram model from the listed file paths.\n",
    "3. Displays the first 10 trigram counts from the combined trigram model.\n",
    "\n",
    "File paths:\n",
    "- 'gutenbergtexts/frankenstein.txt'\n",
    "- 'gutenbergtexts/mobydick.txt'\n",
    "- 'gutenbergtexts/prideandprejudice.txt'\n",
    "- 'gutenbergtexts/romeoandjuliet.txt'\n",
    "- 'gutenbergtexts/scarletletter.txt'\n",
    "\n",
    "The combined trigram model is created by calling the `process_multiple_files` function with the list of file paths.\n",
    "The first 10 trigram counts from the combined trigram model are displayed by converting the model to a list of tuples and printing the first 10 items.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' LE': 2789, 'LET': 1288, 'ETT': 997, 'TTE': 2141, 'TER': 7254, 'ER ': 17193, 'R T': 4524, ' TO': 16087, 'TO ': 14617, 'O M': 1842, ' MR': 1372, 'MRS': 374, 'RS.': 716, 'S. ': 3141, '. S': 1466, ' SA': 3993, 'SAV': 180, 'AVI': 512, 'VIL': 479, 'ILL': 3706, 'LLE': 1195, 'LE ': 6435, 'E E': 2250, ' EN': 2286, 'ENG': 723, 'NGL': 984, 'GLA': 350, 'LAN': 1307, 'AND': 19336, 'ND.': 311, 'D. ': 1902, ' ST': 5071, 'ST.': 309, 'T. ': 2435, '. P': 340, ' PE': 2722, 'PET': 180, 'ETE': 587, 'ERS': 3578, 'RSB': 3, 'SBU': 18, 'BUR': 315, 'URG': 149, 'RGH': 64, 'GH ': 1784, 'H D': 294, ' DE': 4535, 'DEC': 579, 'EC.': 3, 'C. ': 70, '. T': 3299, ' TH': 55432, 'TH ': 7714, 'H .': 11, ' . ': 311, '. Y': 568, ' YO': 5124, 'YOU': 5050, 'OU ': 3929, 'U W': 495, ' WI': 8644, 'WIL': 1842, 'LL ': 7835, 'L R': 313, ' RE': 6192, 'REJ': 103, 'EJO': 52, 'JOI': 192, 'OIC': 276, 'ICE': 1039, 'CE ': 4594, 'E T': 10499, 'O H': 1994, ' HE': 13123, 'HEA': 2504, 'EAR': 4471, 'AR ': 2179, 'THA': 8516, 'HAT': 9320, 'AT ': 12970, 'T N': 1158, ' NO': 8420, 'NO ': 1598, 'O D': 914, ' DI': 3600, 'DIS': 1540, 'ISA': 220, 'SAS': 35, 'AST': 2488, 'STE': 3085, 'R H': 2077, ' HA': 10254, 'HAS': 1089, 'AS ': 11125, 'S A': 7602, ' AC': 1208, 'ACC': 641, 'CCO': 386, 'COM': 2658, 'OMP': 944}\n"
     ]
    }
   ],
   "source": [
    "# List all file paths for 5 different books from Project Gutenberg\n",
    "file_paths = [\n",
    "    'gutenbergtexts/frankenstein.txt',\n",
    "    'gutenbergtexts/mobydick.txt',\n",
    "    'gutenbergtexts/prideandprejudice.txt',\n",
    "    'gutenbergtexts/romeoandjuliet.txt',\n",
    "    'gutenbergtexts/scarletletter.txt'\n",
    "]\n",
    "\n",
    "# Process all the files and build a combined trigram model from the listed file paths\n",
    "combined_trigram_model = process_multiple_files(file_paths)\n",
    "\n",
    "# Display the first 10 trigram counts from the combined trigram model\n",
    "print(dict(list(combined_trigram_model.items())[:100])) # Convert to a list of tuples and display the first 10 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2: Third-order letter approximation generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Prints the possible next characters for a given pair of characters (last_two)\n",
    "and their probabilities based on the trigram model.\n",
    "\n",
    "Args:\n",
    "    trigram_model (dict): The trigram model containing counts of trigrams.\n",
    "    last_two (str): The last two characters (e.g., 'TH') for which to calculate next character probabilities.\n",
    "\n",
    "Returns:\n",
    "    None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_trigram_possibilities(trigram_model, last_two):\n",
    "    \"\"\"\n",
    "    Prints the possible next characters for a given pair of characters (last_two)\n",
    "    and their probabilities based on the trigram model.\n",
    "    \n",
    "    Args:\n",
    "        trigram_model (dict): The trigram model containing counts of trigrams.\n",
    "        last_two (str): The last two characters (e.g., 'TH') for which to calculate next character probabilities.\n",
    "    \"\"\"\n",
    "\n",
    "    # Find all trigrams with the given two characters\n",
    "    possible_trigrams = {trigram: count for trigram, count in trigram_model.items() if trigram.startswith(last_two)}\n",
    "\n",
    "    if not possible_trigrams:\n",
    "        print(f\"No trigrams found starting with '{last_two}'.\")\n",
    "        return\n",
    "    \n",
    "    # Seperate the third letter and their respective counts\n",
    "    letters = [trigram[2] for trigram in possible_trigrams.keys() ]\n",
    "    counts = list(possible_trigrams.values())\n",
    "\n",
    "    # Calculate the total count of occurrence's for normalisation\n",
    "    total_count = sum(counts)\n",
    "\n",
    "    # Print the possibilities\n",
    "    print(f\"Possible next characters after '{last_two}':\")\n",
    "    for letter, count in zip(letters, counts):\n",
    "        probability = count / total_count\n",
    "        print(f\"{last_two + letter}: appeared {count} times, probability = {probability:.4f}\")\n",
    "    print(f\"Total occurrences; {total_count}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of Generated Text\n",
    "\n",
    "The generated text was analyzed to determine the percentage of valid English words. The analysis involved the following steps:\n",
    "\n",
    "1. **Loading Valid Words**:\n",
    "    - A set of valid English words was loaded from the `words.txt` file.\n",
    "\n",
    "2. **Generating Text**:\n",
    "    - Text was generated using the trigram model built from the combined text of five books from Project Gutenberg.\n",
    "\n",
    "3. **Calculating Word Percentage**:\n",
    "    - The generated text was processed to extract individual words.\n",
    "    - Each word was checked against the set of valid English words.\n",
    "    - The percentage of valid English words in the generated text was calculated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated text (first 500 characters):\n",
      "THE FES ISTE OF HE INSWIT TON THERS AN BULT TRACTEM. NACES A LEN PION AS ON WAY \n",
      "AT POSTENY AMONER ALL SEAMEN OT TO HIST SPEADHUNATTLY SHICE SOO SIOUDER AT ID BO\n",
      "TTIMPED HIS OF THERSE WEADTHE BEARTFIC WING UPS ALRE GRE A FORDS UPORM SERING TI\n",
      "ONAHADY HAD GRAD SH I WIFEEN TURE WHAT FANDOGEN BRALL TH A COUS SMUT DUAD DART B\n",
      "E AMORS OF THE WHATTLY RE O CONEE WHISURNIN NAT AND ALLIS ANDS FULD UNTHOUNA LOR\n",
      "DNE AND ISS THE MIS SUS ANT THATUNTHIM FOREEN SAW FIVER HAMING HIL DREST FORWHAM\n",
      " JOY A FRODYIN\n",
      "\n",
      "\n",
      "\n",
      "Possible next characters after 'TH':\n",
      "TH : appeared 7714 times, probability = 0.1080\n",
      "THA: appeared 8516 times, probability = 0.1192\n",
      "THE: appeared 42957 times, probability = 0.6013\n",
      "THI: appeared 5546 times, probability = 0.0776\n",
      "THO: appeared 3509 times, probability = 0.0491\n",
      "THS: appeared 291 times, probability = 0.0041\n",
      "THU: appeared 437 times, probability = 0.0061\n",
      "THR: appeared 1257 times, probability = 0.0176\n",
      "TH.: appeared 290 times, probability = 0.0041\n",
      "THY: appeared 561 times, probability = 0.0079\n",
      "THW: appeared 70 times, probability = 0.0010\n",
      "THL: appeared 94 times, probability = 0.0013\n",
      "THB: appeared 7 times, probability = 0.0001\n",
      "THQ: appeared 9 times, probability = 0.0001\n",
      "THD: appeared 59 times, probability = 0.0008\n",
      "THF: appeared 63 times, probability = 0.0009\n",
      "THH: appeared 17 times, probability = 0.0002\n",
      "THK: appeared 4 times, probability = 0.0001\n",
      "THG: appeared 4 times, probability = 0.0001\n",
      "THT: appeared 15 times, probability = 0.0002\n",
      "THP: appeared 7 times, probability = 0.0001\n",
      "THC: appeared 6 times, probability = 0.0001\n",
      "THN: appeared 2 times, probability = 0.0000\n",
      "THM: appeared 9 times, probability = 0.0001\n",
      "Total occurrences; 71444\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def generate_text(trigram_model, length = 10000, line_length=80):\n",
    "    # Start with the string \"TH\" \n",
    "    generated_text = \"TH\"\n",
    "\n",
    "    # Continue generating characters until reached desired length\n",
    "    while len(generated_text) < length:\n",
    "        # Get the last two characters from the current text\n",
    "        last_two = generated_text[-2:]\n",
    "\n",
    "        # Find all trigrams starting with those two characters\n",
    "        possible_trigrams = {trigram: count for trigram, count in trigram_model.items() if trigram.startswith(last_two)}\n",
    "\n",
    "        if not possible_trigrams:\n",
    "            # In case there are no trigrams starting with the last two characters, stop generating\n",
    "            print(f\"Warning: No trigrams found for the pair '{last_two}'.\")\n",
    "            break\n",
    "\n",
    "        # Separate the third letter and their respective counts\n",
    "        letters = [trigram[2] for trigram in possible_trigrams.keys()]\n",
    "        counts = list(possible_trigrams.values())\n",
    "\n",
    "        next_char = random.choices(letters, weights=counts, k=1)[0]\n",
    "\n",
    "        generated_text += next_char\n",
    "    # Add line breaks at the specified line length (default 80 characters per line)\n",
    "    formatted_text = '\\n'.join([generated_text[i:i+line_length] for i in range(0, len(generated_text), line_length)])\n",
    "\n",
    "    return formatted_text\n",
    "\n",
    "# Generate the text and print possible trigrams for debugging (set debug=True)\n",
    "generated_text = generate_text(combined_trigram_model, length=10000, line_length=80)\n",
    "\n",
    "\n",
    "# Display the first 500 characters of the generated text\n",
    "print(f\"\\nGenerated text (first 500 characters):\\n{generated_text[:500]}\")\n",
    "print(\"\\n\\n\")\n",
    "print_trigram_possibilities(combined_trigram_model, \"TH\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 3. Analyze your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation of `load_words` Function\n",
    "\n",
    "The `load_words` function is designed to load a set of valid English words from a specified file. It reads each line from the file, strips any whitespace (including newline characters) from the ends, and converts each word to lowercase to ensure uniformity. The function returns a set of these valid words, which can be used for various text analysis tasks, such as validating the words in generated text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_words(file_path):\n",
    "     # Open the file located at 'file_path' in read mode\n",
    "    with open(file_path, 'r') as f:\n",
    "        # Use a set comprehension to read each line from the file,\n",
    "        # strip any whitespace (including newline characters) from the ends,\n",
    "        # and convert each word to lowercase to ensure uniformity.\n",
    "        valid_words = {line.strip().lower() for line in f}\n",
    "    # Return the set of valid words loaded from the file\n",
    "    return valid_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Words from Text\n",
    "This function removes punctuation, converts the text to lowercase, and splits it into individual words. \n",
    "It is used to preprocess text for further analysis, ensuring consistency in word extraction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_words(text):\n",
    "    \"\"\"\n",
    "    Extracts words from a given text by splitting on non-alphabetic characters.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The input text to extract words from.\n",
    "        \n",
    "    Returns:\n",
    "        list: A list of extracted words from the text.\n",
    "    \"\"\"\n",
    "\n",
    "    # Remove punctuation and convert to lowercase\n",
    "    translator = str.maketrans('','',string.punctuation)\n",
    "    clean_text = text.translate(translator).lower()\n",
    "\n",
    "    # Split by spaces to get words\n",
    "    words = clean_text.split()\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation of `calculate_word_percentage` Function\n",
    "\n",
    "The `calculate_word_percentage` function is designed to evaluate the coherence of the generated text by calculating the percentage of valid English words it contains. This function performs the following steps:\n",
    "\n",
    "1. **Extract Words from Generated Text**:\n",
    "    - The function uses the `extract_words` function to preprocess the generated text by removing punctuation, converting it to lowercase, and splitting it into individual words.\n",
    "\n",
    "2. **Count Valid Words**:\n",
    "    - Each extracted word is checked against a set of valid English words (`valid_words`).\n",
    "    - The function counts how many of the extracted words are valid English words.\n",
    "\n",
    "3. **Calculate Percentage**:\n",
    "    - The percentage of valid English words is calculated by dividing the count of valid words by the total number of extracted words.\n",
    "    - The function returns the percentage of valid words, the count of valid words, and the total number of words.\n",
    "\n",
    "This function helps in assessing the quality of the generated text by providing a quantitative measure of its validity based on the presence of recognizable English words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_word_percentage(generated_text, valid_words):\n",
    "    \"\"\"\n",
    "    Calculates the percentage of valid English words in the generated text.\n",
    "    \n",
    "    Args:\n",
    "        generated_text (str): The generated text from Task 2.\n",
    "        valid_words (set): A set of valid English words.\n",
    "        \n",
    "    Returns:\n",
    "        float: The percentage of valid words in the text.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract words from the generated text\n",
    "    words = extract_words(generated_text)\n",
    "\n",
    "    # Count the valid words\n",
    "    valid_word_count = sum(1 for word in words if word in valid_words)\n",
    "\n",
    "    # Calculate the percentage of valid words there\n",
    "    total_words = len(words)\n",
    "    percentage = (valid_word_count / total_words) * 100 if total_words > 0 else 0\n",
    "\n",
    "    return percentage, valid_word_count, total_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid words: 702 / 1898\n",
      "Percentage of valid English words: 36.99%\n"
     ]
    }
   ],
   "source": [
    "# Load the valid english words from words.txt\n",
    "valid_words = load_words('data/words.txt')\n",
    "\n",
    "# Use the generated text from Task 2\n",
    "generated_text = generate_text(combined_trigram_model, length=10000)\n",
    "\n",
    "# Calculate the percentage of valid English words\n",
    "percentage, valid_word_count, total_words = calculate_word_percentage(generated_text, valid_words)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Valid words: {valid_word_count} / {total_words}\")\n",
    "print(f\"Percentage of valid English words: {percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 4: Export your model as JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_trigram_model(trigram_model, output_file):\n",
    "    \"\"\"\n",
    "    Exports the trigram model to a JSON file.\n",
    "    \n",
    "    Args:\n",
    "        trigram_model (dict): The trigram model containing counts of trigrams.\n",
    "        output_file (str): The path to the output JSON file.\n",
    "    \"\"\"\n",
    "\n",
    "    # Open the specified output file in write mode\n",
    "    with open(output_file, 'w') as f:\n",
    "        # Use json.dump() to write the trigram model to the file\n",
    "        json.dump(trigram_model, f, indent=4) # indent = 4, this is for nice printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigram model has been exported to trigrams.json\n"
     ]
    }
   ],
   "source": [
    "# Specify the name of the output file where the trigram model will be saved\n",
    "output_file = 'trigrams.json'\n",
    "# Call the function to export the trigram model to a JSON file\n",
    "# 'combined_trigram_model' is the dictionary containing the trigrams and their counts\n",
    "export_trigram_model(combined_trigram_model,output_file)\n",
    "# Print the results\n",
    "print(f\"Trigram model has been exported to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
